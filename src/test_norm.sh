echo "从大到小"
#echo "5e-2"
#python run_textcnn.py --output_dir=./saved_models_1 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/BCB/train_all.jsonl --eval_data_file=datasets/BCB/eval_all.jsonl --test_data_file=datasets/BCB/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 5e-2 --d_size 128 --pkl_file=datasets/BCB/preprocess/path_embeddings_graph_10_v2.pkl
#echo "3e-2"
#python run_textcnn.py --output_dir=./saved_models_1 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/BCB/train_all.jsonl --eval_data_file=datasets/BCB/eval_all.jsonl --test_data_file=datasets/BCB/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 3e-2 --d_size 128 --pkl_file=datasets/BCB/preprocess/path_embeddings_graph_10_v2.pkl
echo "BCB textcnn 2e-2"
python run_textcnn.py --output_dir=./saved_models_1 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/BCB/train_all.jsonl --eval_data_file=datasets/BCB/eval_all.jsonl --test_data_file=datasets/BCB/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 2e-2 --d_size 128 --pkl_file=datasets/BCB/preprocess/path_embeddings_graph_10_v2.pkl
echo "BCB textcnn 8e-3"
python run_textcnn.py --output_dir=./saved_models_1 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/BCB/train_all.jsonl --eval_data_file=datasets/BCB/eval_all.jsonl --test_data_file=datasets/BCB/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 8e-3 --d_size 128 --pkl_file=datasets/BCB/preprocess/path_embeddings_graph_10_v2.pkl
echo "BCB textcnn 7e-3"
python run_textcnn.py --output_dir=./saved_models_1 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/BCB/train_all.jsonl --eval_data_file=datasets/BCB/eval_all.jsonl --test_data_file=datasets/BCB/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 7e-3 --d_size 128 --pkl_file=datasets/BCB/preprocess/path_embeddings_graph_10_v2.pkl
echo "BCB textcnn 5e-3"
python run_textcnn.py --output_dir=./saved_models_1 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/BCB/train_all.jsonl --eval_data_file=datasets/BCB/eval_all.jsonl --test_data_file=datasets/BCB/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 5e-3 --d_size 128 --pkl_file=datasets/BCB/preprocess/path_embeddings_graph_10_v2.pkl

echo "************************************************************************"
echo "BCB attention 8e-3"
python run_multihead_attention.py --output_dir=./saved_models_2 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/BCB/train_all.jsonl --eval_data_file=datasets/BCB/eval_all.jsonl --test_data_file=datasets/BCB/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 8e-3 --d_size 128 --num_head 8 --pkl_file=datasets/BCB/preprocess/path_embeddings_graph_10_v2.pkl
echo "BCB attention 7e-3"
python run_multihead_attention.py --output_dir=./saved_models_2 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/BCB/train_all.jsonl --eval_data_file=datasets/BCB/eval_all.jsonl --test_data_file=datasets/BCB/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 7e-3 --d_size 128 --num_head 8 --pkl_file=datasets/BCB/preprocess/path_embeddings_graph_10_v2.pkl
echo "GCJ textcnn 8e-3"
python run_textcnn.py --output_dir=./saved_models_2 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/GCJ/train_all.jsonl --eval_data_file=datasets/GCJ/eval_all.jsonl --test_data_file=datasets/GCJ/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 8e-3 --d_size 128 --pkl_file=datasets/GCJ/preprocess/path_embeddings_graph_10_v2.pkl
echo "GCJ textcnn 7e-3"
python run_textcnn.py --output_dir=./saved_models_2 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/GCJ/train_all.jsonl --eval_data_file=datasets/GCJ/eval_all.jsonl --test_data_file=datasets/GCJ/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 7e-3 --d_size 128 --pkl_file=datasets/GCJ/preprocess/path_embeddings_graph_10_v2.pkl
echo "GCJ attention 8e-3"
python run_multihead_attention.py --output_dir=./saved_models_2 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/GCJ/train_all.jsonl --eval_data_file=datasets/GCJ/eval_all.jsonl --test_data_file=datasets/GCJ/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 8e-3 --d_size 128 --num_head 8 --pkl_file=datasets/GCJ/preprocess/path_embeddings_graph_10_v2.pkl
echo "GCJ attention 7e-3"
python run_multihead_attention.py --output_dir=./saved_models_2 --model_type=roberta --tokenizer_name=../models/graphcodebert --model_name_or_path=../models/graphcodebert --do_train --do_eval --train_data_file=datasets/GCJ/train_all.jsonl --eval_data_file=datasets/GCJ/eval_all.jsonl --test_data_file=datasets/GCJ/test_all.jsonl --epoch 12 --block_size 512 --train_batch_size 36 --eval_batch_size 36 --learning_rate 1e-4 --max_grad_norm 1.0 --evaluate_during_training --seed 123456 --cnn_size 128 --filter_size 3 --lambda_reg 7e-3 --d_size 128 --num_head 8 --pkl_file=datasets/GCJ/preprocess/path_embeddings_graph_10_v2.pkl

